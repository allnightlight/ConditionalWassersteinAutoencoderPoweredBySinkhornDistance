{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# # To initialize the work environment\n",
    "# %cd /content/drive/My Drive/\n",
    "# !git clone https://github.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/casestudies -b casestudies\n",
    "\n",
    "# # To update the work environment\n",
    "# %cd /content/drive/My Drive/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance\n",
    "# !git pull\n",
    "\n",
    "%cd /content/drive/My Drive/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/casestudies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../framework/\")\n",
    "sys.path.append(\"../sl/\")\n",
    "sys.path.append(\"../wae/\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "\n",
    "from conc_environment_factory import ConcEnvironmentFactory\n",
    "from conc_build_parameter import ConcBuildParameter\n",
    "from conc_build_parameter_factory import ConcBuildParameterFactory\n",
    "from conc_agent_factory import ConcAgentFactory\n",
    "from wae_trainer_factory import WaeTrainerFactory\n",
    "\n",
    "\n",
    "from builder import Builder\n",
    "from store import Store\n",
    "from mylogger import MyLogger\n",
    "\n",
    "from loader import Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbPath = \"training_log.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_casestudy = \"cs01a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_err(buildParameter, agent):\n",
    "    environment = environmentFactory.create(buildParameter)\n",
    "    trainer = trainerFactory.create(buildParameter, agent, environment)\n",
    "\n",
    "    err_latent = []\n",
    "    err_observable = []\n",
    "    for dataBatchEnv in environment.generateBatchDataIterator():\n",
    "        dataBatchAg = agent(dataBatchEnv)\n",
    "        _err_latent, _ = trainer.measure_distance(dataBatchAg._Xi, dataBatchAg._XiHat)\n",
    "        _err_observable = torch.mean(torch.abs(dataBatchAg._XHat - dataBatchEnv._X))\n",
    "\n",
    "        err_latent.append(_err_latent.data.numpy())\n",
    "        err_observable.append(_err_observable.data.numpy())\n",
    "    err_latent = np.mean(err_latent)\n",
    "    err_observable = np.mean(err_observable)\n",
    "    \n",
    "    return err_observable, err_latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S400: Load trained agents to analyze them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SS410: initialize a loader of trained agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agentFactory = ConcAgentFactory()\n",
    "environmentFactory = ConcEnvironmentFactory()\n",
    "trainerFactory =  WaeTrainerFactory()\n",
    "\n",
    "store = Store(dbPath)\n",
    "\n",
    "buildParameterFactory = ConcBuildParameterFactory()\n",
    "loader = Loader(agentFactory=agentFactory\n",
    "                , environmentFactory=environmentFactory\n",
    "                , buildParameterFactory=buildParameterFactory\n",
    "                , store = store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SS420: evaluate trained agents:\n",
    "\n",
    "evaluation error is here:\n",
    "* the representitive errors of observable variables\n",
    "* and the discrepancy between latent referenced distribution and the one projected by trained encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = {\n",
    "    \"representative_error\": []\n",
    "    , \"latent_distribution_discrepancy\": []\n",
    "      }\n",
    "for agent, buildParameter, epoch in loader.load(target_casestudy + \"%\"):\n",
    "    \n",
    "    for key in buildParameter.__dict__:\n",
    "        if not key in tbl:\n",
    "            tbl[key] = []\n",
    "        tbl[key].append(buildParameter.__dict__[key])\n",
    "    \n",
    "    err_observable, err_latent = evaluate_err(buildParameter, agent)\n",
    "    \n",
    "    tbl[\"representative_error\"].append(err_observable)\n",
    "    tbl[\"latent_distribution_discrepancy\"].append(err_latent)\n",
    "    \n",
    "tbl = pd.DataFrame(tbl)\n",
    "tbl.to_csv(target_casestudy +  \"_error.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
